\chapter{算法分析}
当我们在研究算法时，需要分析算法是否正确以及是否高效，以便于挑选出最优的算法加以使用。

一个正确的算法需要保证对于所有规模的输入都能给出正确的输出。因此，在证明算法的正确性时，
我们往往使用数学归纳法。

一个高效的算法需要在输入规模较大时仍能较为快速地给出输出，为此，我们使用渐进分析来描述
算法的效率。
\section{RAM模型}
为了简化分析算法的过程，我们要对运行算法的机器进行建模以及简化。我们所采用的模型被称为RAM模型，即“Random Access Model”，其中的核心假设如下：
\begin{enumerate}
    \item 内存(memory)由一系列字(word)组成，可以像数组编号，并通过编号访问
    \item CPU一次只能取出一个字，并对其进行操作
    \item 获取一个字只需要一个基本操作。因此我们假设一个字所含的比特数$w=c\lg n$，其中$n$为数据规模，这保证了其能够在一个字内处理所需数据的编号。
\end{enumerate}
\section{循环不变量}
通常一个算法中有一个或多个循环语句，并且某些关键性质通过这些循环进行维护，从开始到结束保持着某种不变量。
这种不变量我们称其为“循环不变量”。

给定一个核心为循环的算法，首先我们要找出其中的“循环不变量”，然后进行归纳证明。归纳证明主要分为3步：
\begin{enumerate}
    \item {\cuhei 初始状态：}循环不变量是否在进入第一轮循环之前正确
    \item {\cuhei 维护：}如果循环不变量在某一轮循环之前正确，它是否在进入下一轮循环之前保持正确
    \item {\cuhei 结束状态：}当循环结束时，该循环不变量能否提供有用的性质以便于说明该算法的正确性
\end{enumerate}
对于{\code\bfseries for}语句而言，这三部的时机分别位于：1）计数器赋初值之后（严格而言并且是在判断循环是否结束之前）；
2）执行循环体然后计数器更新这一过程；3）计数器更新导致循环结束后。也就是说，对于{\code\bfseries for}语句，计数器初始化代表着整个循环语句的初始化，
但是和任何一轮循环无关；一轮循环依次包括：检查循环是否结束、执行循环体、更新计数器。
\section{渐进分析}
在本节中讨论的函数的定义域都是正整数，并且当自变量足够大时，函数值为正。
\begin{mydef}[渐进符号]
    \[
    \begin{array}{rcl}
     O(g(n))&=&\{f(n):\exists c,n_0>0\quad s.t.\quad\forall n\geq n_0\quad f(n)/g(n)\leq c\}\\
    \Omega(g(n))&=&\{f(n):\exists c,n_0>0\quad s.t.\quad\forall n\geq n_0\quad f(n)/g(n)\geq c\}\\
    \Theta(g(n))&=&\{f(n):\exists c_1,c_2,n_0>0\quad s.t.\quad\forall n\geq n_0\quad c_1\leq f(n)/g(n)\leq c_2\}\\
    o(g(n))&=&\{f(n):\lim_{n\rightarrow\infty}f(n)/g(n)=0\}\\
    \omega(g(n))&=&\{f(n):\lim_{n\rightarrow\infty}f(n)/g(n)=\infty\}\\
    \end{array}
    \]
\end{mydef}
\begin{myrmk}
    记忆渐进符号中$f,g$的相对关系可以进行如下理解：渐进符号是一个集合，有许多函数，而该渐进符号却用一个函数来代表这个集合，那么这个函数是有特殊意义的，也就是
    各个渐进符号的含义。例如$O(f)$就是一个函数的集合，其中的函数的一个紧上界为$f$。
\end{myrmk}
$O(g(n)),o(g(n))$中的函数的上界均可以用$g(n)$来描述，区别在于前者的上界是“紧”的，而后者是“松”的——给出的上界远远超过实际值。
类似地，
$\Omega(g(n)),\omega(g(n))$中的函数的下界均可以用$g(n)$来描述，区别在于前者的下界是“紧”的，而后者是“松”的——给出的下界远远小于实际值。
而$\Theta(g(n))$中的函数可以由$g(n)$给出一个“紧”的估计。

渐近符号$O,\Omega,\Theta,o,\omega$可以分别比作$\leq,\geq,=,<,>$，享有着对应符号的性质，例如传递性，对称性等。但是，渐进符号不具有三歧性。
\section{分治法}
分治法是设计算法的常用方法之一，它主要分为三步：分割、解决以及合并。它的主要思想便是将一个规模较大的问题拆分成多个规模较小的问题，然后分别解决这些较小的问题，最后
将这些较小问题的解答合并，从而得到原先问题的解答。分治法通常涉及到递归，它的时间复杂度的一般形式为
\[T(n)=\begin{cases}
    \Theta(1)&\text{if }n\leq c,\\
    aT(n/b)+D(n)+C(n)&\text{otherwise.}\\
\end{cases}\]
这表示：1）我们假设当问题规模降低到一定程度时，便可以在常数时间内解决；2）当问题规模较大时，我们将原先规模为$n$的问题拆分为$a$个规模为$n/b$的子问题， 将它们分别
解决后然后进行合并，其中$D(n),C(n)$分别表示拆分和合并所需要的时间，我们也可以用$f(n)$来表示它们之和。
\begin{myrmk}
    一般而言，每个阶段我们将拆分得到多个\emph{规模相同的，且结构和原问题一致的子问题}。如果我们需要拆分出来结构和原问题发生较大变化的子问题，我们则将它对应的
    时间复杂度算入合并所需的时间中。
\end{myrmk}

这也就意味着，分析使用分治法的算法的时间复杂度时，需要求解一个递推函数。为此，本节将介绍三种求解方法。
\subsection{替换法}
替换法的核心步骤为
\begin{enumerate}
    \item 猜测解的形式
    \item 使用数学归纳法进行证明
\end{enumerate}
第一步通常需要较多的经验。当然也可以通过不断缩小上下界来找到紧的界。

在进行数学归纳法的证明时，我们可能会在证明初始情况遇到困难，此时我们可以将初始情况进行适当调整，因为我们进行的是渐进分析。
在证明递推情况时，我们可能也会遇到问题，此时的解决方法通常是在原先估计的基础上，减去一个低阶量。
\begin{myrmk}
    通过减去低阶量，往往能够使得我们的归纳假设变得更强，从而更轻松地完成证明。
\end{myrmk}
\subsection{递归树法}
递归树法便是通过绘制树状的复杂度分布图来进行分析：从上至下，每一层代表着一层递归，结点上标明对应的时间复杂度，然后将每层的时间复杂度
进行求和，最终再对所有层的时间复杂度进行求和，得到整个算法的时间复杂度。

递归树法主要用于辅助替代法寻找到解的形式，因此在使用递归树法时，我们可以适当化简问题，例如忽略取整符号、限制问题规模为某个整数的倍数等等
——我们只需找到解的形式，然后利用数学归纳法进行严格证明。
\subsection{主定理法}
\begin{mythm}
    设常数$a\geq 1,b>1$，$f(n)$为一个函数，并令$T(n)$为定义域为非负整数的函数，且
    \[T(n)=aT(n/b)+f(n),\]
    其中$n/b$可以视为$\lfloor n/b\rfloor$或$\lceil n/b\rceil$。那么$T(n)$有如下渐进界：
    \begin{enumerate}
        \item 如果$f(n)=O(n^{\log_ba-\epsilon})$，其中$\epsilon$为某正数，则$T(n)=\Theta(n^{\log_ba})$。
        \item 如果$f(n)=\Theta(n^{\log_ba})$，则$T(n)=\Theta(n^{\log_ba}\lg n)$。
        \item 如果$f(n)=\Omega(n^{\log_ba+\epsilon})$，其中$\epsilon$为某正数，同时
       $af(n/b)\leq cf(n)$对于某个常数$c<1$当$n$足够大时成立， 则$T(n)=\Theta(f(n))$。
    \end{enumerate}
\end{mythm}
\begin{myrmk}
   $\log_ba$中的$a,b$的位置可以用$aT(n/b)$中的位置来辅助记忆。

   渐进符号也和 $\log_ab$相对于 $f(n)$的关系相吻合。
\end{myrmk}
该定理将情况按照 $f(n)$与$n^{\log_ba}$相对渐进关系进行分类讨论。总的而言，该定理指出，两个哪个更“大”，则哪个是是
所求的解，如果一样“大”，则解为$\Theta(n^{\log_ba}\lg n)=\Theta(f(n)\lg n)$。

进一步，在第一个情况中，要求$f(n)$以多项式级别渐进小于$\log_ba$；在第三个情况中，要求$f(n)$以多项式级别渐进大于$\log_ba$，
同时，还需要满足“正则条件”$af(n/b)\leq cf(n)$。
\section{概率分析与随机算法}
算法分为确定性算法和随机算法。对于确定性算法，给定一个输入，输出也就确定了；而对于随机算法，给定一个输入，
每次的输出可能不同。这也就意味着，对于随机算法，并没有特定的输入会导致最坏时间复杂度。

对于确定性算法，它的输入可能是随机的，或者说是服从一定分布的。对于随机算法也是，但是随机算法可能会进一步对其进行随机化处理，
改变输入原有的分布，使得对于同一个输入，用于实际运算的数据有所不同。例如某个算法的输入是 $n$元排序，原有的输入可能服从一定的分布，但是我们可以设计一个随机算法，
在开头将输入进行随机转置，从而将其视为服从均匀分布，此时我们实际上无需对输入原来服从的分布作任何假设。
\begin{myrmk}
    “转置服从均匀分布”指的是成为任何一种可能的转置都是等概率的。
\end{myrmk}
当算法的输入服从一定的分布时，我们将考虑了该分布后得出的时间复杂度称为平均时间复杂度。
而当算法自身引入随机性时，我们称该算法的时间复杂度为期望时间复杂度
\subsection{示性随机变量}
示性随机变量常常配合期望的线性性来辅助对于期望的分析。
\begin{mydef}[示性随机变量$I$]
    \[I\{A\}=\begin{cases}
        1& \text{if A occurs,}\\
        0& \text{if A does not occur.}
    \end{cases}\]
\end{mydef}
显然， 令 $X_A=I\{A\}$，则 $E[X_A]=Pr\{A\}$